// Code generated by layout. DO NOT EDIT.

package base

import (
	"encoding/binary"
	"fmt"
	"io"
	"unsafe"
)

func (p *PageHeader) MarshalLayout() ([]byte, error) {
	buf := make([]byte, 24)

	// PageID: PageID at [0, 8)
	binary.LittleEndian.PutUint64(buf[0:8], uint64(p.PageID))

	// Flags: uint16 at [8, 10)
	binary.LittleEndian.PutUint16(buf[8:10], p.Flags)

	// NumKeys: uint16 at [10, 12)
	binary.LittleEndian.PutUint16(buf[10:12], p.NumKeys)

	// Padding: uint32 at [12, 16)
	binary.LittleEndian.PutUint32(buf[12:16], p.Padding)

	// TxnID: uint64 at [16, 24)
	binary.LittleEndian.PutUint64(buf[16:24], p.TxnID)

	return buf, nil
}

func (p *PageHeader) UnmarshalLayout(buf []byte) error {
	if len(buf) != 24 {
		return fmt.Errorf("expected 24 bytes, got %d", len(buf))
	}

	// PageID: PageID at [0, 8)
	p.PageID = PageID(binary.LittleEndian.Uint64(buf[0:8]))

	// Flags: uint16 at [8, 10)
	p.Flags = binary.LittleEndian.Uint16(buf[8:10])

	// NumKeys: uint16 at [10, 12)
	p.NumKeys = binary.LittleEndian.Uint16(buf[10:12])

	// Padding: uint32 at [12, 16)
	p.Padding = binary.LittleEndian.Uint32(buf[12:16])

	// TxnID: uint64 at [16, 24)
	p.TxnID = binary.LittleEndian.Uint64(buf[16:24])

	return nil
}

func (p *LeafElement) MarshalLayout() ([]byte, error) {
	buf := make([]byte, 16)

	// KeyOffset: uint16 at [0, 2)
	binary.LittleEndian.PutUint16(buf[0:2], p.KeyOffset)

	// KeySize: uint16 at [2, 4)
	binary.LittleEndian.PutUint16(buf[2:4], p.KeySize)

	// ValueOffset: uint16 at [4, 6)
	binary.LittleEndian.PutUint16(buf[4:6], p.ValueOffset)

	// ValueSize: uint16 at [6, 8)
	binary.LittleEndian.PutUint16(buf[6:8], p.ValueSize)

	// Reserved: uint64 at [8, 16)
	binary.LittleEndian.PutUint64(buf[8:16], p.Reserved)

	return buf, nil
}

func (p *LeafElement) UnmarshalLayout(buf []byte) error {
	if len(buf) != 16 {
		return fmt.Errorf("expected 16 bytes, got %d", len(buf))
	}

	// KeyOffset: uint16 at [0, 2)
	p.KeyOffset = binary.LittleEndian.Uint16(buf[0:2])

	// KeySize: uint16 at [2, 4)
	p.KeySize = binary.LittleEndian.Uint16(buf[2:4])

	// ValueOffset: uint16 at [4, 6)
	p.ValueOffset = binary.LittleEndian.Uint16(buf[4:6])

	// ValueSize: uint16 at [6, 8)
	p.ValueSize = binary.LittleEndian.Uint16(buf[6:8])

	// Reserved: uint64 at [8, 16)
	p.Reserved = binary.LittleEndian.Uint64(buf[8:16])

	return nil
}

func (p *BranchElement) MarshalLayout() ([]byte, error) {
	buf := make([]byte, 16)

	// KeyOffset: uint16 at [0, 2)
	binary.LittleEndian.PutUint16(buf[0:2], p.KeyOffset)

	// KeySize: uint16 at [2, 4)
	binary.LittleEndian.PutUint16(buf[2:4], p.KeySize)

	// Reserved: uint32 at [4, 8)
	binary.LittleEndian.PutUint32(buf[4:8], p.Reserved)

	// ChildID: PageID at [8, 16)
	binary.LittleEndian.PutUint64(buf[8:16], uint64(p.ChildID))

	return buf, nil
}

func (p *BranchElement) UnmarshalLayout(buf []byte) error {
	if len(buf) != 16 {
		return fmt.Errorf("expected 16 bytes, got %d", len(buf))
	}

	// KeyOffset: uint16 at [0, 2)
	p.KeyOffset = binary.LittleEndian.Uint16(buf[0:2])

	// KeySize: uint16 at [2, 4)
	p.KeySize = binary.LittleEndian.Uint16(buf[2:4])

	// Reserved: uint32 at [4, 8)
	p.Reserved = binary.LittleEndian.Uint32(buf[4:8])

	// ChildID: PageID at [8, 16)
	p.ChildID = PageID(binary.LittleEndian.Uint64(buf[8:16]))

	return nil
}

func NewLeafPage() *LeafPage {
	p := &LeafPage{}
	// IMPORTANT: AllocatePageBuffer() must return a buffer of at least 4096 bytes
	p.backing = AllocatePageBuffer()
	
	// Validate buffer size to prevent out-of-bounds access
	if len(p.backing) < 4096 {
		panic(fmt.Sprintf("AllocatePageBuffer returned buffer of %d bytes, need at least 4096", len(p.backing)))
	}
	
	// Use buffer directly (no alignment required)
	p.buf = p.backing[:4096]
	
	// Initialize dynamic slices
	// Data: end-start region, initialized during unmarshal
	return p
}

func (p *LeafPage) MarshalLayout() ([]byte, error) {
	// Header: PageHeader at [0, 24)
	elemBuf, err := p.Header.MarshalLayout()
	if err != nil {
		return nil, fmt.Errorf("marshal Header: %w", err)
	}
	copy(p.buf[0:24], elemBuf)

	// Elements: []LeafElement at [24, 4096) with count=Header.NumKeys (element size: 16)
	if len(p.Elements) != int(p.Header.NumKeys) {
		return nil, fmt.Errorf("Elements length mismatch: have %d, want %d", len(p.Elements), p.Header.NumKeys)
	}
	offset := 24
	for i := range p.Elements {
		if offset + 16 > 4096 {
			return nil, fmt.Errorf("Elements collision at offset %d", offset)
		}
		elemBuf, err := p.Elements[i].MarshalLayout()
		if err != nil {
			return nil, fmt.Errorf("marshal Elements[%d]: %w", i, err)
		}
		copy(p.buf[offset:offset+16], elemBuf)
		offset += 16
	}

	// Data: []byte at [4096, 24)
	// Data is already sliced from p.buf, no copy needed

	return p.buf[:], nil
}

func (p *LeafPage) UnmarshalLayout(buf []byte) error {
	// Zero-copy mode: copy buf into p.buf if different
	if len(buf) > 0 && len(p.buf) > 0 {
		if &buf[0] != &p.buf[0] {
			copy(p.buf, buf)
		}
	}

	// Header: PageHeader at [0, 24)
	if err := p.Header.UnmarshalLayout(p.buf[0:24]); err != nil {
		return fmt.Errorf("unmarshal Header: %w", err)
	}

	// Elements: []LeafElement at [24, 4096) with count=Header.NumKeys (element size: 16)
	// Reuse slice if capacity allows
	if cap(p.Elements) >= int(p.Header.NumKeys) {
		p.Elements = p.Elements[:p.Header.NumKeys]
	} else {
		p.Elements = make([]LeafElement, p.Header.NumKeys)
	}
	offset := 24
	for i := range p.Elements {
		if err := p.Elements[i].UnmarshalLayout(p.buf[offset:offset+16]); err != nil {
			return fmt.Errorf("unmarshal Elements[%d]: %w", i, err)
		}
		offset += 16
	}

	// Data: []byte at [4096, 24)
	// Data: end-start data region, set by indirect slice reconstruction

	// Keys: [][]byte from=Elements offset=KeyOffset size=KeySize region=Data
	// Initialize Data data region after metadata
	elementsEnd := 24 + int(p.Header.NumKeys)*16
	p.Data = p.buf[elementsEnd:4096]

	// Reuse slice if capacity allows
	if cap(p.Keys) >= len(p.Elements) {
		p.Keys = p.Keys[:len(p.Elements)]
	} else {
		p.Keys = make([][]byte, len(p.Elements))
	}
	for i := range p.Elements {
		offset := int(p.Elements[i].KeyOffset)
		size := int(p.Elements[i].KeySize)
		// Offset is absolute from page start, adjust to region-relative
		regionOffset := offset - elementsEnd
		p.Keys[i] = p.Data[regionOffset:regionOffset+size]
	}

	// Values: [][]byte from=Elements offset=ValueOffset size=ValueSize region=Data
	// Reuse slice if capacity allows
	if cap(p.Values) >= len(p.Elements) {
		p.Values = p.Values[:len(p.Elements)]
	} else {
		p.Values = make([][]byte, len(p.Elements))
	}
	for i := range p.Elements {
		offset := int(p.Elements[i].ValueOffset)
		size := int(p.Elements[i].ValueSize)
		// Offset is absolute from page start, adjust to region-relative
		regionOffset := offset - elementsEnd
		p.Values[i] = p.Data[regionOffset:regionOffset+size]
	}

	return nil
}

func (p *LeafPage) LoadFrom(r io.Reader) error {
	if _, err := io.ReadFull(r, p.buf[:]); err != nil {
		return err
	}
	return p.UnmarshalLayout(p.buf)
}

func (p *LeafPage) WriteTo(w io.Writer) error {
	if _, err := p.MarshalLayout(); err != nil {
		return err
	}
	_, err := w.Write(p.buf[:])
	return err
}

// RebuildIndirectSlices rebuilds the physical layout from logical slices
// Call this after modifying Keys/Values before calling MarshalLayout
func (p *LeafPage) RebuildIndirectSlices() {
	// Calculate where Elements ends
	elementsEnd := 24 + int(p.Header.NumKeys)*16
	
	// Initialize Data buffer after Elements
	p.Data = p.buf[elementsEnd:elementsEnd:4096]
	
	// Save non-indirect metadata fields before rebuilding Elements
	savedElements := make([]LeafElement, len(p.Elements))
	copy(savedElements, p.Elements)
	
	// Rebuild Elements array
	if cap(p.Elements) >= int(p.Header.NumKeys) {
		p.Elements = p.Elements[:p.Header.NumKeys]
	} else {
		p.Elements = make([]LeafElement, p.Header.NumKeys)
	}
	
	// Pack indirect slices into Data region backward from end
	offset := 4096
	
	// Pack all indirect slices backward from end (elements in forward order)
	for i := 0; i < len(p.Keys); i++ {
		// Pack Keys[i]
		size0 := len(p.Keys[i])
		offset -= size0
		copy(p.buf[offset:offset+size0], p.Keys[i])
		p.Elements[i].KeyOffset = uint16(offset)
		p.Elements[i].KeySize = uint16(size0)
		// Pack Values[i]
		size1 := len(p.Values[i])
		offset -= size1
		copy(p.buf[offset:offset+size1], p.Values[i])
		p.Elements[i].ValueOffset = uint16(offset)
		p.Elements[i].ValueSize = uint16(size1)

		// Restore non-indirect fields (only if saved element exists)
		if i < len(savedElements) {
			p.Elements[i].Reserved = savedElements[i].Reserved
		}
	}
	
	// Update Data to span full packed region
	p.Data = p.buf[elementsEnd:4096]
}

func NewBranchPage() *BranchPage {
	p := &BranchPage{}
	// IMPORTANT: AllocatePageBuffer() must return a buffer of at least 4096 bytes
	p.backing = AllocatePageBuffer()
	
	// Validate buffer size to prevent out-of-bounds access
	if len(p.backing) < 4096 {
		panic(fmt.Sprintf("AllocatePageBuffer returned buffer of %d bytes, need at least 4096", len(p.backing)))
	}
	
	// Use buffer directly (no alignment required)
	p.buf = p.backing[:4096]
	
	// Initialize dynamic slices
	// Data: end-start region, initialized during unmarshal
	return p
}

func (p *BranchPage) MarshalLayout() ([]byte, error) {
	// Header: PageHeader at [0, 24)
	elemBuf, err := p.Header.MarshalLayout()
	if err != nil {
		return nil, fmt.Errorf("marshal Header: %w", err)
	}
	copy(p.buf[0:24], elemBuf)

	// Elements: []BranchElement at [24, 4088) with count=Header.NumKeys (element size: 16)
	if len(p.Elements) != int(p.Header.NumKeys) {
		return nil, fmt.Errorf("Elements length mismatch: have %d, want %d", len(p.Elements), p.Header.NumKeys)
	}
	offset := 24
	for i := range p.Elements {
		if offset + 16 > 4088 {
			return nil, fmt.Errorf("Elements collision at offset %d", offset)
		}
		elemBuf, err := p.Elements[i].MarshalLayout()
		if err != nil {
			return nil, fmt.Errorf("marshal Elements[%d]: %w", i, err)
		}
		copy(p.buf[offset:offset+16], elemBuf)
		offset += 16
	}

	// FirstChild: PageID at [4088, 4096)
	*(*uint64)(unsafe.Pointer(&p.buf[4088])) = uint64(p.FirstChild)

	// Data: []byte at [4096, 4096)
	// Data is already sliced from p.buf, no copy needed

	return p.buf[:], nil
}

func (p *BranchPage) UnmarshalLayout(buf []byte) error {
	// Zero-copy mode: copy buf into p.buf if different
	if len(buf) > 0 && len(p.buf) > 0 {
		if &buf[0] != &p.buf[0] {
			copy(p.buf, buf)
		}
	}

	// Header: PageHeader at [0, 24)
	if err := p.Header.UnmarshalLayout(p.buf[0:24]); err != nil {
		return fmt.Errorf("unmarshal Header: %w", err)
	}

	// Elements: []BranchElement at [24, 4088) with count=Header.NumKeys (element size: 16)
	// Reuse slice if capacity allows
	if cap(p.Elements) >= int(p.Header.NumKeys) {
		p.Elements = p.Elements[:p.Header.NumKeys]
	} else {
		p.Elements = make([]BranchElement, p.Header.NumKeys)
	}
	offset := 24
	for i := range p.Elements {
		if err := p.Elements[i].UnmarshalLayout(p.buf[offset:offset+16]); err != nil {
			return fmt.Errorf("unmarshal Elements[%d]: %w", i, err)
		}
		offset += 16
	}

	// FirstChild: PageID at [4088, 4096)
	p.FirstChild = PageID(*(*uint64)(unsafe.Pointer(&p.buf[4088])))

	// Data: []byte at [4096, 4096)
	// Data: end-start data region, set by indirect slice reconstruction

	// Keys: [][]byte from=Elements offset=KeyOffset size=KeySize region=Data
	// Initialize Data data region after metadata
	elementsEnd := 24 + int(p.Header.NumKeys)*16
	p.Data = p.buf[elementsEnd:4096]

	// Reuse slice if capacity allows
	if cap(p.Keys) >= len(p.Elements) {
		p.Keys = p.Keys[:len(p.Elements)]
	} else {
		p.Keys = make([][]byte, len(p.Elements))
	}
	for i := range p.Elements {
		offset := int(p.Elements[i].KeyOffset)
		size := int(p.Elements[i].KeySize)
		// Offset is absolute from page start, adjust to region-relative
		regionOffset := offset - elementsEnd
		p.Keys[i] = p.Data[regionOffset:regionOffset+size]
	}

	return nil
}

func (p *BranchPage) LoadFrom(r io.Reader) error {
	if _, err := io.ReadFull(r, p.buf[:]); err != nil {
		return err
	}
	return p.UnmarshalLayout(p.buf)
}

func (p *BranchPage) WriteTo(w io.Writer) error {
	if _, err := p.MarshalLayout(); err != nil {
		return err
	}
	_, err := w.Write(p.buf[:])
	return err
}

// RebuildIndirectSlices rebuilds the physical layout from logical slices
// Call this after modifying Keys/Values before calling MarshalLayout
func (p *BranchPage) RebuildIndirectSlices() {
	// Calculate where Elements ends
	elementsEnd := 24 + int(p.Header.NumKeys)*16
	
	// Initialize Data buffer after Elements
	p.Data = p.buf[elementsEnd:elementsEnd:4096]
	
	// Save non-indirect metadata fields before rebuilding Elements
	savedElements := make([]BranchElement, len(p.Elements))
	copy(savedElements, p.Elements)
	
	// Rebuild Elements array
	if cap(p.Elements) >= int(p.Header.NumKeys) {
		p.Elements = p.Elements[:p.Header.NumKeys]
	} else {
		p.Elements = make([]BranchElement, p.Header.NumKeys)
	}
	
	// Pack indirect slices into Data region backward from end
	offset := 4096
	
	// Pack all indirect slices backward from end (elements in forward order)
	for i := 0; i < len(p.Keys); i++ {
		// Pack Keys[i]
		size0 := len(p.Keys[i])
		offset -= size0
		copy(p.buf[offset:offset+size0], p.Keys[i])
		p.Elements[i].KeyOffset = uint16(offset)
		p.Elements[i].KeySize = uint16(size0)

		// Restore non-indirect fields (only if saved element exists)
		if i < len(savedElements) {
			p.Elements[i].Reserved = savedElements[i].Reserved
			p.Elements[i].ChildID = savedElements[i].ChildID
		}
	}
	
	// Update Data to span full packed region
	p.Data = p.buf[elementsEnd:4096]
}

func NewOverflowPage() *OverflowPage {
	p := &OverflowPage{}
	// IMPORTANT: AllocatePageBuffer() must return a buffer of at least 4096 bytes
	p.backing = AllocatePageBuffer()
	
	// Validate buffer size to prevent out-of-bounds access
	if len(p.backing) < 4096 {
		panic(fmt.Sprintf("AllocatePageBuffer returned buffer of %d bytes, need at least 4096", len(p.backing)))
	}
	
	// Use buffer directly (no alignment required)
	p.buf = p.backing[:4096]
	
	// Initialize dynamic slices
	p.Data = p.buf[36:36:4096]
	return p
}

func (p *OverflowPage) MarshalLayout() ([]byte, error) {
	// Header: PageHeader at [0, 24)
	elemBuf, err := p.Header.MarshalLayout()
	if err != nil {
		return nil, fmt.Errorf("marshal Header: %w", err)
	}
	copy(p.buf[0:24], elemBuf)

	// NextPage: PageID at [24, 32)
	*(*uint64)(unsafe.Pointer(&p.buf[24])) = uint64(p.NextPage)

	// DataSize: uint32 at [32, 36)
	*(*uint32)(unsafe.Pointer(&p.buf[32])) = p.DataSize

	// Data: []byte at [36, 4096) with count=DataSize
	// Data is already sliced from p.buf, no copy needed

	return p.buf[:], nil
}

func (p *OverflowPage) UnmarshalLayout(buf []byte) error {
	// Zero-copy mode: copy buf into p.buf if different
	if len(buf) > 0 && len(p.buf) > 0 {
		if &buf[0] != &p.buf[0] {
			copy(p.buf, buf)
		}
	}

	// Header: PageHeader at [0, 24)
	if err := p.Header.UnmarshalLayout(p.buf[0:24]); err != nil {
		return fmt.Errorf("unmarshal Header: %w", err)
	}

	// NextPage: PageID at [24, 32)
	p.NextPage = PageID(*(*uint64)(unsafe.Pointer(&p.buf[24])))

	// DataSize: uint32 at [32, 36)
	p.DataSize = *(*uint32)(unsafe.Pointer(&p.buf[32]))

	// Data: []byte at [36, 4096) with count=DataSize
	p.Data = p.buf[36:36+p.DataSize]

	return nil
}

func (p *OverflowPage) LoadFrom(r io.Reader) error {
	if _, err := io.ReadFull(r, p.buf[:]); err != nil {
		return err
	}
	return p.UnmarshalLayout(p.buf)
}

func (p *OverflowPage) WriteTo(w io.Writer) error {
	if _, err := p.MarshalLayout(); err != nil {
		return err
	}
	_, err := w.Write(p.buf[:])
	return err
}

